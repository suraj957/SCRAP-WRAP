# ğŸ§µ Scrap â€¢ Wrap â€” URL Q&A Chatbot

Scrap â€¢ Wrap is a lightweight Retrieval-Augmented Generation (RAG) chatbot that allows you to paste any webpage or PDF URL, embed its content into a local FAISS vector store, and chat naturally about it â€” fully locally or optionally powered by OpenAI.

Built with **Streamlit**, **LangChain**, **FAISS**, and **SQLite** for persistent chat history.

---

## ğŸš€ Features

- ğŸ”— **URL ingestion** â€” Scrape, clean, and embed text from any webpage or PDF  
- âš™ï¸ **FAISS index persistence per URL**  
- ğŸ’¬ **ChatGPT-style interface** with memory & multiple conversations  
- ğŸ§  Supports **local (llama.cpp)** or **remote (OpenAI)** LLMs  
- âš¡ **Streaming responses** in real time  
- ğŸ“‚ **Persistent chat history** stored in SQLite  
- ğŸ§© **Instant index load** using `load_index_only()` (no re-scraping)  
- ğŸ§¾ Works with both **HTML** and **PDFs**

---

## ğŸ—‚ï¸ Folder Structure

url-chatbot/
â”œâ”€â”€ app.py # Streamlit UI + chat logic
â”œâ”€â”€ retriever.py # RAG pipeline + FAISS handling
â”œâ”€â”€ scraper.py # Scraper (Trafilatura, BeautifulSoup, PDF)
â”œâ”€â”€ storage.py # SQLite storage for conversations/messages
â”œâ”€â”€ vectorstore/ # FAISS indexes (auto-created)
â”œâ”€â”€ .env # Model + backend config
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md


---

## ğŸ§° Prerequisites

- Python **3.9 â€“ 3.11**
- Works on **macOS**, **Linux**, or **Windows (WSL)**
- For local models â†’ **llama.cpp GGUF file**
- For remote models â†’ **OpenAI API key**

---

## âš™ï¸ Installation

```bash
# 1. Clone the repository
git clone https://github.com/<your-username>/url-chatbot.git
cd url-chatbot

# 2. Create a virtual environment
python -m venv .venv
# Activate:
#   Windows: .venv\Scripts\activate
#   macOS/Linux: source .venv/bin/activate

# 3. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# 4. Create folders
mkdir -p vectorstore models

## ğŸ”‘ .env Configuration

### ğŸ§  Local model (llama.cpp)

```env
LLM_BACKEND=llamacpp
MODEL_PATH=models/mistral-7b-instruct-v0.1.Q4_K_M.gguf

EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
STORE_DIR=vectorstore

# Performance tuning (optional)
N_THREADS=8
N_BATCH=512
N_GPU_LAYERS=20
USE_MMAP=true
USE_MLOCK=false
